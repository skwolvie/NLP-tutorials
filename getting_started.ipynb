{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-REFERENCES\n",
    "\n",
    "1. http://www.nltk.org/book/\n",
    "2. https://course.spacy.io/en/\n",
    "3. https://github.com/mhagiwara/100-nlp-papers\n",
    "4. https://github.com/keon/awesome-nlp\n",
    "5. https://github.com/shashankg7/Deep-Learning-for-NLP-Resources\n",
    "6. http://cs224d.stanford.edu/syllabus.html\n",
    "7. https://www.kaggle.com/learn/natural-language-processing\n",
    "8. https://www.youtube.com/playlist?list=PL8FFE3F391203C98C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with any NLP problem involves the following steps:\n",
    "1. Problem Identification, and shortlisting plausible NLP Models that can be applied\n",
    "\n",
    "OVERUSED NLP APPLICATIONS:\n",
    "    1. Sentiment Analysis (vader, bert)\n",
    "    2. Topic Analysis\n",
    "    3. Similarity models\n",
    "    4. Keyword Extraction\n",
    "    5. Classification and clusterning (applications of topic, keyword, sentiment, similarity)\n",
    "    6. Summarization\n",
    "    7. Text Generation\n",
    "\n",
    "2. Corpous/ Dataset Selection\n",
    "\n",
    "3. Cleaning the corpous (very important)\n",
    "    1. Cleaning unwanted patterns (email, emoji, urls)\n",
    "    2. Removal of stop words\n",
    "    3. Removal of most repeated and least repeated words\n",
    "    4. Removal of symbols, special charecters\n",
    "    5. Stemming or lemmatization\n",
    "    5. Tokenization splitting on ' ' or some special charecter\n",
    "    - 2 or more meaningful words are joined together, spell checker (Spark NLP) \n",
    "    6. N-Gram cobinations of splitted tokens\n",
    "    7. POS Tagging, NER Tagging, removal of unwanted taged words\n",
    "\n",
    "4. Testing models that solve a problem\n",
    "   Each class of NLP applications can have multiple approaches, we have test and opt the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "#### Extract skill keywords from given job description and then cluster those keywords to give meaningful skill clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "from ast import literal_eval\n",
    "punc=string.punctuation\n",
    "print(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\31405\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "st = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(r'D:\\OneDrive - Indian School of Business\\Projects_archive\\JSI\\archive\\JSI Project\\JSI_Naukri\\data\\ntwrk_scrape\\data.csv', low_memory=False, nrows= 500)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   jobTitle        500 non-null    object \n",
      " 1   jobId           500 non-null    float64\n",
      " 2   jobType         440 non-null    object \n",
      " 3   currency        500 non-null    object \n",
      " 4   posted_days     500 non-null    object \n",
      " 5   companyName     500 non-null    object \n",
      " 6   tags            500 non-null    object \n",
      " 7   companyId       500 non-null    float64\n",
      " 8   jobdescription  500 non-null    object \n",
      " 9   functionalarea  500 non-null    object \n",
      " 10  scraping_date   500 non-null    object \n",
      " 11  posted_date     500 non-null    object \n",
      " 12  monthYear       500 non-null    object \n",
      " 13  salary          500 non-null    object \n",
      " 14  experience      492 non-null    object \n",
      " 15  education       0 non-null      float64\n",
      " 16  location        500 non-null    object \n",
      "dtypes: float64(3), object(14)\n",
      "memory usage: 66.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(literal_eval(\"{'name': 'sachin'}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>Dear Candidate,</p><br/><p>We are looking to hire Graduates who can speak English & Hindi for Tally ERP support.</p><p> </p><p>JD:</p><ul><li>Role: To provide voice support to Tally customers from all over India and across the globe</li><li>Qualification: Any Graduate having basic knowledge of accounts and ready to work in an Accounts process</li><li>Must possess good communication skills in Hindi & English</li><li>Terms & Conditions: Need to submit 10th & 12th original marks card for a period of 16 months</li><li>Shifts: Willing to work in different day shifts starting from 9:00am to 7:30pm (girls) and 10:30am to 9:30pm (boys) based on 9 hour working</li><li>Remuneration: Best in the industry</li></ul><p> </p><p>Interested candidates can walk in with your updated profile to the below mentioned address;</p><p> </p><p><strong>Abhilash Nair,</strong> HR Assistant Manager - <strong>9789830683</strong></p><p><strong>Greet Technologies Pvt Ltd</strong></p><p>327-328, 6th Sector, 5th Main Service Road, HSR Layout, Bengaluru, 560102</p><p>Walk-In Timing: 10:30am to 5:30pm</p>',\n",
       " 'com,CA(Inter),CMA(Inter),CS(Inter) / CA / CS / CMA can apply<br><br>Should have knowledge in finalization of accounts,Auditing in Tally,Taxation work of individuals,firms,and companies<br><br>Supervision and training will be provided for good candidates who are interested in learning and self motivating',\n",
       " 'We are looking for fresher candidates for Executive to handle Accounting,TDS,GST,Income tax,ROC compliance,ROC,all taxation,and all audits related to the companyFreshers will be trained.CA INTER/ CMA INTER/ CS INTER / CA / CMA / CS also can applySalary is not a constraint for the right candidate<br><br>work: 0 - 1 year (Preferred) <br><br>Bcom,MBA (Preferred) ',\n",
       " 'Any Graduate BBA / BBM / BCom / MCom / MBA Finance / Commerce Background Only 2017 / 2018 / 2019 Passed Out<br><br>Standing arrear is not eligible,Should be all cleared<br><br>Minimum 0 -2 Years of Experience into Accounts / Finance / Audit',\n",
       " '<p> </p><p>Position : Chartered Accountant-Chennai (Corporate Audit Services, Chennai), freshers are also accepted with first attempt throughout.</p><br/><p>Qualification : 1st attempt Chartered Accountant</p><br/><p>Experience : 0-3 years (Post CA Final qualification)</p><br/><p>Areas of Exposure/Work Background : Experience in Internal / external Audits preferably in construction / infra projects. Sound knowledge of accounting and auditing standards, IFRS. Qualification / experience in forensic accounting/audit would be added advantage.</p><br/><p>Purpose of the position :</p><p>To help complete the audit plan and OE testing of ICFR</p><br/><p>Job Profile :</p><p>Primary :</p><p>To work as a part of a team of professionally qualified accountants, carry out the audits and issue audit reports. Travelling is must for auditing at different locations. (15 days in a month).</p><br/><p>Secondary:</p><p>To work on achieving other departmental objectives like OE testing of ICFR, developing data analytics, contribute auditing system etc. </p><br/><p>Location : Chennai</p><br/><p>Please attach your CV and mention the Current CTC</p><p><br/></p>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['jobdescription'].head().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(re.escape(i), '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in st])\n",
    "\n",
    "def removeNumbers(text):\n",
    "    \"\"\" Removes integers \"\"\"\n",
    "    text = ''.join([i for i in text if not i.isdigit()])         \n",
    "    return text\n",
    "\n",
    "def remove_punc(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in punc])\n",
    "\n",
    "def clean_text(lst):\n",
    "    # remove twitter Return handles (RT @xxx:)\n",
    "    # lst = np.vectorize(remove_pattern)(lst, \"RT @[\\w]*:\")\n",
    "    # remove twitter handles (@xxx)\n",
    "    # lst = np.vectorize(remove_pattern)(lst, \"@[\\w]*\")\n",
    "    # remove URL links (httpxxx)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"https?://[A-Za-z0-9./]*\")\n",
    "    # remove special tags\n",
    "    lst= np.vectorize(remove_pattern)(lst, \"<(.*?)>\")\n",
    "    lst = np.core.defchararray.replace(lst, \"[^a-zA-Z]\", \"\")\n",
    "    return str(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jobdescription']= df['jobdescription'].str.replace('nan', '')\n",
    "df['jobdescription']= df['jobdescription'].apply(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<>Dear Candidate,</><><>We are looking to hire Graduates who can seak Engsh & Hindi for Tally ERP suort.</><> </><>JD:</><><>Role: To rovide voice suort to Tally customers from all over India and across the globe</><>Quafication: Any Graduate having basic knowledge of accounts and ready to work in an Accounts rocess</><>Must ossess good communication skills in Hindi & Engsh</><>Terms & Conditions: Need to submit 10th & 12th original marks card for a eriod of 16 months</><>Shifts: Wilng to work in different day shifts starting from 9:00am to 7:30m (girls) and 10:30am to 9:30m (boys) based on 9 hour working</><>Remuneration: Best in the industry</></><> </><>Interested candidates can walk in with your udated rofile to the below mentioned address;</><> </><><>Abhilash Nair,</> HR Assistant Manager - <>9789830683</></><><>Greet Technologies Pvt Ltd</></><>327-328, 6th Sector, 5th Main Service Road, HSR Layout, Bengaluru, 560102</><>Walk-In Timing: 10:30am to 5:30m</>',\n",
       " 'com,CA(Inter),CMA(Inter),CS(Inter) / CA / CS / CMA can apply<><>Should have knowledge in finalization of accounts,Auditing in Tally,Taxation work of individuals,firms,and companies<><>Supervision and training will be provided for good candidates who are interested in learning and self motivating',\n",
       " 'We are looking for fresher candidates for Executive to handle Accounting,TDS,GST,Income tax,ROC compliance,ROC,all taxation,and all audits related to the companyFreshers will be trained.CA INTER/ CMA INTER/ CS INTER / CA / CMA / CS also can applySalary is not a constraint for the right candidate<><>work: 0 - 1 year (Preferred) <><>Bcom,MBA (Preferred) ',\n",
       " 'Any Graduate BBA / BBM / BCom / MCom / MBA Fice / Commerce Background Only 2017 / 2018 / 2019 Passed Out<><>Standing arrear is not eligible,Should be all cleared<><>Minimum 0 -2 Years of Experience into Accounts / Fice / Audit',\n",
       " '<> </><>Position : Chartered Accountant-Chennai (Cororate Audit Services, Chennai), freshers are also acceted with first attemt throughout.</><><>Qualification : 1st attemt Chartered Accountant</><><>Exerience : 0-3 years (Post CA Final qualification)</><><>Areas of Exosure/Work Background : Exerience in Internal / external Audits referably in construction / infra rojects. Sound knowledge of accounting and auditing standards, IFRS. Qualification / exerience in forensic accounting/audit would be added advantage.</><><>Purose of the osition :</><>To hel comlete the audit lan and OE testing of ICFR</><><>Job Profile :</><>Primary :</><>To work as a art of a team of rofessionally qualified accountants, carry out the audits and issue audit reorts. Travelling is must for auditing at different locations. (15 days in a month).</><><>Secondary:</><>To work on achieving other deartmental objectives like OE testing of ICFR, develoing data analytics, contribute auditing system etc. </><><>Location : Chennai</><><>Please attach your CV and mention the Current CTC</><><></>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['jobdescription'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-a0206b9dfe17>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['jobdescription']= df['jobdescription'].str.replace('[^\\w\\s]','')\n",
      "<ipython-input-16-a0206b9dfe17>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['jobdescription']= df['jobdescription'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "df['jobdescription']= df['jobdescription'].str.replace('[^\\w\\s]','')\n",
    "df['jobdescription']= df['jobdescription'].str.lower()\n",
    "df['jobdescription']= df['jobdescription'].apply(lambda text: remove_stop_words(text))\n",
    "df['jobdescription']= df['jobdescription'].apply(lambda text: removeNumbers(text))\n",
    "df['jobdescription']= df['jobdescription'].apply(lambda text: remove_punc(text))\n",
    "df['jobdescription']= df['jobdescription'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dear candidatewe looking hire graduates seak engsh hindi tally erp suort jdrole rovide voice suort tally customers india across globequafication graduate basic knowledge accounts ready work accounts rocessmust ossess good communication skills hindi engshterms conditions need submit th th original marks card eriod monthsshifts wilng work different day shifts starting am m girls am m boys based hour workingremuneration best industry interested candidates walk udated rofile mentioned address abhilash nair hr assistant manager greet technologies pvt ltd th sector th main service road hsr layout bengaluru walkin timing am m',\n",
       " 'comcaintercmaintercsinter ca cs cma applyshould knowledge finalization accountsauditing tallytaxation work individualsfirmsand companiessupervision training provided good candidates interested learning self motivating',\n",
       " 'looking fresher candidates executive handle accountingtdsgstincome taxroc compliancerocall taxationand audits related companyfreshers trainedca inter cma inter cs inter ca cma cs also applysalary constraint right candidatework year preferred bcommba preferred',\n",
       " 'graduate bba bbm bcom mcom mba fice commerce background passed outstanding arrear eligibleshould clearedminimum years experience accounts fice audit',\n",
       " 'position chartered accountantchennai cororate audit services chennai freshers also acceted first attemt throughoutqualification st attemt chartered accountantexerience years post ca final qualificationareas exosurework background exerience internal external audits referably construction infra rojects sound knowledge accounting auditing standards ifrs qualification exerience forensic accountingaudit would added advantagepurose osition hel comlete audit lan oe testing icfrjob profile primary work art team rofessionally qualified accountants carry audits issue audit reorts travelling must auditing different locations days monthsecondaryto work achieving deartmental objectives like oe testing icfr develoing data analytics contribute auditing system etc location chennaiplease attach cv mention current ctc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['jobdescription'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split joined keywords\n",
    "# NER Tagging\n",
    "# spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\31405\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['position chartered accountantchennai cororate audit services chennai freshers also acceted first attemt throughoutqualification st attemt chartered accountantexerience years post ca final qualificationareas exosurework background exerience internal external audits referably construction infra rojects sound knowledge accounting auditing standards ifrs qualification exerience forensic accountingaudit would added advantagepurose osition hel comlete audit lan oe testing icfrjob profile primary work art team rofessionally qualified accountants carry audits issue audit reorts travelling must auditing different locations days monthsecondaryto work achieving deartmental objectives like oe testing icfr develoing data analytics contribute auditing system etc location chennaiplease attach cv mention current ctc']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sent_tokenize in module nltk.tokenize:\n",
      "\n",
      "sent_tokenize(text, language='english')\n",
      "    Return a sentence-tokenized copy of *text*,\n",
      "    using NLTK's recommended sentence tokenizer\n",
      "    (currently :class:`.PunktSentenceTokenizer`\n",
      "    for the specified language).\n",
      "    \n",
      "    :param text: text to split into sentences\n",
      "    :param language: the model name in the Punkt corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['position',\n",
       " 'chartered',\n",
       " 'accountantchennai',\n",
       " 'cororate',\n",
       " 'audit',\n",
       " 'services',\n",
       " 'chennai',\n",
       " 'freshers',\n",
       " 'also',\n",
       " 'acceted',\n",
       " 'first',\n",
       " 'attemt',\n",
       " 'throughoutqualification',\n",
       " 'st',\n",
       " 'attemt',\n",
       " 'chartered',\n",
       " 'accountantexerience',\n",
       " 'years',\n",
       " 'post',\n",
       " 'ca',\n",
       " 'final',\n",
       " 'qualificationareas',\n",
       " 'exosurework',\n",
       " 'background',\n",
       " 'exerience',\n",
       " 'internal',\n",
       " 'external',\n",
       " 'audits',\n",
       " 'referably',\n",
       " 'construction',\n",
       " 'infra',\n",
       " 'rojects',\n",
       " 'sound',\n",
       " 'knowledge',\n",
       " 'accounting',\n",
       " 'auditing',\n",
       " 'standards',\n",
       " 'ifrs',\n",
       " 'qualification',\n",
       " 'exerience',\n",
       " 'forensic',\n",
       " 'accountingaudit',\n",
       " 'would',\n",
       " 'added',\n",
       " 'advantagepurose',\n",
       " 'osition',\n",
       " 'hel',\n",
       " 'comlete',\n",
       " 'audit',\n",
       " 'lan',\n",
       " 'oe',\n",
       " 'testing',\n",
       " 'icfrjob',\n",
       " 'profile',\n",
       " 'primary',\n",
       " 'work',\n",
       " 'art',\n",
       " 'team',\n",
       " 'rofessionally',\n",
       " 'qualified',\n",
       " 'accountants',\n",
       " 'carry',\n",
       " 'audits',\n",
       " 'issue',\n",
       " 'audit',\n",
       " 'reorts',\n",
       " 'travelling',\n",
       " 'must',\n",
       " 'auditing',\n",
       " 'different',\n",
       " 'locations',\n",
       " 'days',\n",
       " 'monthsecondaryto',\n",
       " 'work',\n",
       " 'achieving',\n",
       " 'deartmental',\n",
       " 'objectives',\n",
       " 'like',\n",
       " 'oe',\n",
       " 'testing',\n",
       " 'icfr',\n",
       " 'develoing',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'contribute',\n",
       " 'auditing',\n",
       " 'system',\n",
       " 'etc',\n",
       " 'location',\n",
       " 'chennaiplease',\n",
       " 'attach',\n",
       " 'cv',\n",
       " 'mention',\n",
       " 'current',\n",
       " 'ctc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('position', 'NN'), ('chartered', 'VBD'), ('accountantchennai', 'JJ'), ('cororate', 'NN'), ('audit', 'NN'), ('services', 'NNS'), ('chennai', 'NN'), ('freshers', 'NNS'), ('also', 'RB'), ('acceted', 'VBD'), ('first', 'JJ'), ('attemt', 'JJ'), ('throughoutqualification', 'NN'), ('st', 'NN'), ('attemt', 'NN'), ('chartered', 'VBN'), ('accountantexerience', 'NN'), ('years', 'NNS'), ('post', 'NN'), ('ca', 'MD'), ('final', 'JJ'), ('qualificationareas', 'NNS'), ('exosurework', 'VBP'), ('background', 'JJ'), ('exerience', 'NN'), ('internal', 'JJ'), ('external', 'JJ'), ('audits', 'NN'), ('referably', 'RB'), ('construction', 'NN'), ('infra', 'NN'), ('rojects', 'VBZ'), ('sound', 'JJ'), ('knowledge', 'NN'), ('accounting', 'NN'), ('auditing', 'NN'), ('standards', 'NNS'), ('ifrs', 'JJ'), ('qualification', 'NN'), ('exerience', 'NN'), ('forensic', 'JJ'), ('accountingaudit', 'NN'), ('would', 'MD'), ('added', 'VBD'), ('advantagepurose', 'JJ'), ('osition', 'NN'), ('hel', 'NN'), ('comlete', 'JJ'), ('audit', 'NN'), ('lan', 'NN'), ('oe', 'IN'), ('testing', 'VBG'), ('icfrjob', 'NN'), ('profile', 'NN'), ('primary', 'JJ'), ('work', 'NN'), ('art', 'NN'), ('team', 'NN'), ('rofessionally', 'RB'), ('qualified', 'VBD'), ('accountants', 'NNS'), ('carry', 'VBP'), ('audits', 'NNS'), ('issue', 'VB'), ('audit', 'NN'), ('reorts', 'NNS'), ('travelling', 'VBG'), ('must', 'MD'), ('auditing', 'VBG'), ('different', 'JJ'), ('locations', 'NNS'), ('days', 'NNS'), ('monthsecondaryto', 'VBP'), ('work', 'NN'), ('achieving', 'VBG'), ('deartmental', 'JJ'), ('objectives', 'NNS'), ('like', 'IN'), ('oe', 'JJ'), ('testing', 'VBG'), ('icfr', 'JJ'), ('develoing', 'VBG'), ('data', 'NNS'), ('analytics', 'NNS'), ('contribute', 'VBP'), ('auditing', 'VBG'), ('system', 'NN'), ('etc', 'FW'), ('location', 'NN'), ('chennaiplease', 'NN'), ('attach', 'NN'), ('cv', 'JJ'), ('mention', 'NN'), ('current', 'JJ'), ('ctc', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "txt='position chartered accountantchennai cororate audit services chennai freshers also acceted first attemt throughoutqualification st attemt chartered accountantexerience years post ca final qualificationareas exosurework background exerience internal external audits referably construction infra rojects sound knowledge accounting auditing standards ifrs qualification exerience forensic accountingaudit would added advantagepurose osition hel comlete audit lan oe testing icfrjob profile primary work art team rofessionally qualified accountants carry audits issue audit reorts travelling must auditing different locations days monthsecondaryto work achieving deartmental objectives like oe testing icfr develoing data analytics contribute auditing system etc location chennaiplease attach cv mention current ctc'\n",
    "tokenized = sent_tokenize(txt, )\n",
    "\n",
    "for i in tokenized:\n",
    "    # Word tokenizers is used to find the words \n",
    "    # and punctuation in a string\n",
    "    wordsList = nltk.word_tokenize(i)\n",
    "  \n",
    "    # removing stop words from wordList\n",
    "    wordsList = [w for w in wordsList if not w in st] \n",
    "  \n",
    "    #  Using a Tagger. Which is part-of-speech \n",
    "    # tagger or POS-tagger. \n",
    "    tagged = nltk.pos_tag(wordsList) \n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('san', 991),\n",
       " ('experience', 383),\n",
       " ('knowledge', 289),\n",
       " ('accounting', 249),\n",
       " ('good', 224),\n",
       " ('years', 198),\n",
       " ('accounts', 186),\n",
       " ('skills', 183),\n",
       " ('work', 161),\n",
       " ('stylefontszetsan', 159),\n",
       " ('stylefontfamly', 158),\n",
       " ('candidate', 131),\n",
       " ('ficial', 123),\n",
       " ('communication', 120),\n",
       " ('new', 119),\n",
       " ('required', 115),\n",
       " ('business', 110),\n",
       " ('team', 109),\n",
       " ('working', 107),\n",
       " ('exerience', 106),\n",
       " ('must', 100),\n",
       " ('excel', 96),\n",
       " ('management', 95),\n",
       " ('tally', 92),\n",
       " ('gst', 86),\n",
       " ('qottmes', 78),\n",
       " ('roman', 78),\n",
       " ('qotserfsan', 77),\n",
       " ('sales', 75),\n",
       " ('tax', 73),\n",
       " ('account', 71),\n",
       " ('fice', 70),\n",
       " ('ms', 69),\n",
       " ('day', 68),\n",
       " ('audit', 64),\n",
       " ('data', 64),\n",
       " ('bank', 64),\n",
       " ('sap', 61),\n",
       " ('ca', 60),\n",
       " ('office', 59),\n",
       " ('end', 58),\n",
       " ('erp', 56),\n",
       " ('able', 54),\n",
       " ('timely', 54),\n",
       " ('customer', 54),\n",
       " ('roles', 53),\n",
       " ('written', 50),\n",
       " ('degree', 50),\n",
       " ('tds', 50),\n",
       " ('related', 49),\n",
       " ('job', 49),\n",
       " ('candidates', 48),\n",
       " ('etc', 48),\n",
       " ('role', 47),\n",
       " ('langenin', 47),\n",
       " ('software', 45),\n",
       " ('strong', 45),\n",
       " ('internal', 44),\n",
       " ('well', 44),\n",
       " ('industry', 43),\n",
       " ('rocess', 43),\n",
       " ('monthly', 43),\n",
       " ('information', 43),\n",
       " ('process', 43),\n",
       " ('key', 43),\n",
       " ('entries', 42),\n",
       " ('time', 42),\n",
       " ('looking', 41),\n",
       " ('activities', 41),\n",
       " ('ensure', 41),\n",
       " ('reorting', 41),\n",
       " ('invoices', 41),\n",
       " ('excellent', 40),\n",
       " ('accountant', 40),\n",
       " ('vendor', 40),\n",
       " ('customers', 39),\n",
       " ('requirement', 39),\n",
       " ('returns', 39),\n",
       " ('minimum', 39),\n",
       " ('executive', 38),\n",
       " ('cash', 38),\n",
       " ('er', 36),\n",
       " ('ayment', 36),\n",
       " ('handling', 36),\n",
       " ('preferred', 35),\n",
       " ('bcom', 35),\n",
       " ('profile', 35),\n",
       " ('benefits', 35),\n",
       " ('per', 35),\n",
       " ('english', 34),\n",
       " ('graduate', 33),\n",
       " ('us', 33),\n",
       " ('acconting', 33),\n",
       " ('reort', 33),\n",
       " ('within', 33),\n",
       " ('manager', 32),\n",
       " ('statutory', 32),\n",
       " ('issues', 32),\n",
       " ('inter', 31),\n",
       " ('system', 31)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "\n",
    "for text in df[\"jobdescription\"].values:\n",
    "    for word in text.split(' '):\n",
    "        cnt[word] += 1\n",
    "cnt.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF- Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
